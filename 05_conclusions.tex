\chapter{Conclusion}\label{ch:conclusion}

\section{Conclusions}\label{sec:conclusions}
The goal of this dissertation was to implement vision-based RAN\@.
The proposed solution allowed us to use Computer Vision techniques to extract relevant information and introduce messages to the RAN\@.

Leveraging the O-RAN architecture, this work demonstrated the seamless integration of sensing and telecommunications technologies.
The convergence of these fields highlights the potential of CV to significantly improve the efficiency and intelligence of 5G networks.

The implementation utilized the open-source software of OpenAirInterface for the 5G Core Network and RAN\@.
The Near-RT RIC was implemented using FlexRIC software.
The Vision Module was developed using OpenCV, Ultralytics YOLO, and BoT-SORT for object detection and tracking.
USRP B210 SDR boards were used to enable communications between UE and gNB\@.
The developed xApp monitored and processed the data, showcasing the practical application of CV in enhancing 5G network performance.

Through the development of the proposed solution we faced some challenges.
lack of documentation in OpenAirInterface and FlexRIC
lack of documentation of library asn1c
instabilities caused by the board.
- relaunched the sofware and unplug and replug.

time contrains

working on two different areas.

In summary, this dissertation illustrates the feasibility and advantages of integrating CV technologies within 5G networks, paving the way for future advancements in telecommunications.



The open-source software used to implement the 5G Core Network and RAN was OpenAirInterface.
The developed VM used OpenCV, Ultralytics YOLO and BoT-SORT to detect and track objects.
USRP B210 SDR boards were used to enable communications between UE and gNB\@.
Finally, the developed xApp monitored.

\section{Known Limitations and Future Work}\label{sec:fut_work}
While this dissertation successfully met its objectives, the system has several limitations, which present opportunities for further enhancements and future work.

The VM could benefit from refinements.
These include the optimization of parameters, determining the optimal number of frames required to accurately obtain tracks, and enhancing the prediction capabilities of the messages.
Additionally, employing two cameras to capture depth information would enable the extraction of more precise location of obstacles and UEs.
Scaling the solution to manage multiple UEs simultaneously is another area for improvement.
The current implementation also faced performance constraints due to hardware limitations, necessitating the use of dedicated hardware for real-time operation.

For the information exchange between the RAN and the Vision Module, utilizing the E2 interface could enhance communication efficiency.

Future work could also involve integrating the xApp with a robotic platform, enabling it to autonomously reposition the gNB\@.
Additionally, the performance limitations of the Software Defined Radios (SDRs) need to be addressed to ensure more robust and reliable communications.

Finally, extending the tests to include millimeter Wave (mmWave) frequencies would provide valuable insights into the system's performance in different operational scenarios, further validating and improving the proposed solution.



% refine parameters in the vision module -
% periodicity of messages
% future blockage enhancement such as no duplicates

% test in better hardware?

%\begin{enumerate}
%    \item Only predicts for one UE
%    \item Camera resolution needs to be at least 360p -- check
%    \item Camera FPS
%    \item Computational power limited. Could use other tracking solutions
%    \item Lighting condition
    
%\end{enumerate}


%FUTURE WORK - have 2 cameras in order to have depth information and extract (x,y,z) location of the obstacles and UEs. Scale the work for several UEs. Use interface E2 to communicate with the xApps.