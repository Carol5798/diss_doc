%bibtex entries 

@ARTICLE{Synthesia,
  author={Cheng, Xiang and Zhang, Haotian and Zhang, Jianan and Gao, Shijian and Li, Sijiang and Huang, Ziwei and Bai, Lu and Yang, Zonghui and Zheng, Xinhu and Yang, Liuqing},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Intelligent Multi-Modal Sensing-Communication Integration: Synesthesia of Machines}, 
  year={2024},
  volume={26},
  number={1},
  pages={258-301},
  keywords={Sensors;Radar;Surveys;6G mobile communication;Wireless communication;Radio frequency;5G mobile communication;Synesthesia of machines;B5G/6G;artificial neural networks;mixed multi-modal dataset;channel modeling;channel estimation;dual-function waveform design;beamforming;environment sensing},
  doi={10.1109/COMST.2023.3336917}}

@techreport{ITU_T_C691,
    title        = {ITU-T Recommendation C.691 - Information technology – ASN.1 encoding rules: Specification of Packed Encoding Rules (PER)},
    author       = {{International Telecommunication Union}},
    institution  = {ITU-T},
    year         = {2022},
}


@techreport{E2GAP,
    title        = {ORAN Near-Real-time RAN Intelligent Controller Architecture \& E2 General Aspects and Principles 2.02},
    author       = {{O-RAN Alliance}},
    institution  = {{O-RAN Working Group 3}},
    number       = {O-RAN.WG3.E2GAP-v02.02},
    year         = {2022},
    month        = {July},
}

@techreport{ORAN_E2SM,
    title        = {Near-Real-time RAN Intelligent Controller E2 Service Model (E2SM), RAN Function Network Interface (NI)},
    author       = {{O-RAN Alliance}},
    institution  = {{O-RAN Working Group 3}},
    number       = {OORAN-WG3.E2SM-NI-v01.00.00},
    year         = {2020},
    month        = {January},
}


@InProceedings{ViWi,
author = {Alrabeiah, M. and Hredzak, A. and Liu, Z. and Alkhateeb, A.},
title = {ViWi: A Deep Learning Dataset Framework for Vision-Aided Wireless Communications},
booktitle = {submitted to IEEE Vehicular Technology Conference},
year = {2019},
month = {Nov.},
}

@ARTICLE{deepsense,
  author={Alkhateeb, Ahmed and Charan, Gouranga and Osman, Tawfik and Hredzak, Andrew and Morais, Joao and Demirhan, Umut and Srinivas, Nikhil},
  journal={IEEE Communications Magazine}, 
  title={DeepSense 6G: A Large-Scale Real-World Multi-Modal Sensing and Communication Dataset}, 
  year={2023},
  volume={61},
  number={9},
  pages={122-128},
  keywords={Sensors;6G mobile communication;Data collection;Millimeter wave communication;Laser radar;Wireless communication;Global Positioning System},
  doi={10.1109/MCOM.006.2200730}}


@INPROCEEDINGS{Goncalo,
  author={Queirós, Gonçalo and Correia, Paulo and Coelho, André and Ricardo, Manuel},
  booktitle={2024 19th Wireless On-Demand Network Systems and Services Conference (WONS)}, 
  title={Autonomous Control and Positioning of a Mobile Radio Access Node Employing the O- RAN Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={25-28},
  keywords={Wireless communication;Wireless sensor networks;5G mobile communication;Computer architecture;Software;Standards;Backhaul networks;6G;Mobile Radio Access Network;O-RAN;xApp},
  doi={10.23919/WONS60642.2024.10449499}}

@INPROCEEDINGS{David,
  author={Maia, David and Coelho, André and Ricardo, Manuel},
  booktitle={2022 18th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)}, 
  title={Obstacle-aware On-demand 5G Network using a Mobile Robotic Platform}, 
  year={2022},
  volume={},
  number={},
  pages={470-473},
  keywords={Wireless communication;Visualization;5G mobile communication;Robot vision systems;Web pages;Prototypes;Cameras;5G;Core Network;Mobile Radio Access Network;Network Function;On-Demand Communications},
  doi={10.1109/WiMob55322.2022.9941633}}



@article{botsort,
  title={BoT-SORT: Robust Associations Multi-Pedestrian Tracking},
  author={Aharon, Nir and Orfaig, Roy and Bobrovsky, Ben-Zion},
  journal={arXiv preprint arXiv:2206.14651},
  year={2022}
}

@INPROCEEDINGS{CVAided,
  author={Charan, Gouranga and Alkhateeb, Ahmed},
  booktitle={2022 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Computer Vision Aided Blockage Prediction in Real-World Millimeter Wave Deployments}, 
  year={2022},
  volume={},
  number={},
  pages={1711-1716},
  keywords={Wireless communication;Visualization;Computer vision;Wireless sensor networks;Switches;Machine learning;Cameras;computer vision;deep learning;blockage prediction;mmWave;terahertz.},
  doi={10.1109/GCWkshps56602.2022.10008524}}




@article{6G_SOA,
   abstract = {Fifth generation (5G) mobile communication systems have entered the stage of commercial deployment, providing users with new services, improved user experiences as well as a host of novel opportunities to various industries. However, 5G still faces many challenges. To address these challenges, international industrial, academic, and standards organizations have commenced research on sixth generation (6G) wireless communication systems. A series of white papers and survey papers have been published, which aim to define 6G in terms of requirements, application scenarios, key technologies, etc. Although ITU-R has been working on the 6G vision and it is expected to reach a consensus on what 6G will be by mid-2023, the related global discussions are still wide open and the existing literature has identified numerous open issues. This paper first provides a comprehensive portrayal of the 6G vision, technical requirements, and application scenarios, covering the current common understanding of 6G. Then, a critical appraisal of the 6G network architecture and key technologies is presented. Furthermore, existing testbeds and advanced 6G verification platforms are detailed for the first time. In addition, future research directions and open challenges are identified to stimulate the on-going global debate. Finally, lessons learned to date concerning 6G networks are discussed.},
   author = {Cheng Xiang Wang and Xiaohu You and Xiqi Gao and Xiuming Zhu and Zixin Li and Chuan Zhang and Haiming Wang and Yongming Huang and Yunfei Chen and Harald Haas and John S. Thompson and Erik G. Larsson and Marco Di Renzo and Wen Tong and Peiying Zhu and Xuemin Shen and H. Vincent Poor and Lajos Hanzo},
   doi = {10.1109/COMST.2023.3249835},
   issn = {1553877X},
   issue = {2},
   journal = {IEEE Communications Surveys and Tutorials},
   keywords = {6G application scenarios,6G challenges,6G key performance indicators (KPIs),6G key technologies,6G network architecture,6G testbeds,6G vision},
   pages = {905-974},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {On the Road to 6G: Visions, Requirements, Key Technologies, and Testbeds},
   volume = {25},
   year = {2023},
}
@article{6G_ITU,
  title={6G Vision: An Ultra-Flexible Perspective},
  author={Yazar, Ahmet and Dogan Tusha, Seda and Arslan, Huseyin},
  journal={ITU Journal on Future and Evolving Technologies},
  volume={1},
  number={1},
  pages={1--12},
  year={2020},
  note={Corresponding author: Ahmet Yazar (ayazar@medipol.edu.tr)}
}

@article{Polese2023,
   abstract = {The Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance specifications are poised to revolutionize the telecom ecosystem. O-RAN promotes virtualized RANs where disaggregated components are connected via open interfaces and optimized by intelligent controllers. The result is a new paradigm for the RAN design, deployment, and operations: O-RAN networks can be built with multi-vendor, interoperable components, and can be programmatically optimized through a centralized abstraction layer and data-driven closed-loop control. Therefore, understanding O-RAN, its architecture, its interfaces, and workflows is key for researchers and practitioners in the wireless community. In this article, we present the first detailed tutorial on O-RAN. We also discuss the main research challenges and review early research results. We provide a deep dive of the O-RAN specifications, describing its architecture, design principles, and the O-RAN interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to effectively control and manage 3GPP-defined RANs. Based on this, we discuss innovations and challenges of O-RAN networks, including the Artificial Intelligence (AI) and Machine Learning (ML) workflows that the architecture and interfaces enable, security, and standardization issues. Finally, we review experimental research platforms that can be used to design and test O-RAN networks, along with recent research results, and we outline future directions for O-RAN development.},
   author = {Michele Polese and Leonardo Bonati and Salvatore D'Oro and Stefano Basagni and Tommaso Melodia},
   doi = {10.1109/COMST.2023.3239220},
   issn = {1553877X},
   issue = {2},
   journal = {IEEE Communications Surveys and Tutorials},
   keywords = {5G,6G,O-RAN,Open RAN,cellular},
   pages = {1376-1411},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges},
   volume = {25},
   year = {2023},
}

@article{obj_detec_SOA,
   abstract = {Object detection and tracking is one of the most important and challenging branches in computer vision, and have been widely applied in various fields, such as health-care monitoring, autonomous driving, anomaly detection, and so on. With the rapid development of deep learning (DL) networks and GPU’s computing power, the performance of object detectors and trackers has been greatly improved. To understand the main development status of object detection and tracking pipeline thoroughly, in this survey, we have critically analyzed the existing DL network-based methods of object detection and tracking and described various benchmark datasets. This includes the recent development in granulated DL models. Primarily, we have provided a comprehensive overview of a variety of both generic object detection and specific object detection models. We have enlisted various comparative results for obtaining the best detector, tracker, and their combination. Moreover, we have listed the traditional and new applications of object detection and tracking showing its developmental trends. Finally, challenging issues, including the relevance of granular computing, in the said domain are elaborated as a future scope of research, together with some concerns. An extensive bibliography is also provided.},
   author = {Sankar K. Pal and Anima Pramanik and J. Maiti and Pabitra Mitra},
   doi = {10.1007/s10489-021-02293-7},
   issn = {15737497},
   issue = {9},
   journal = {Applied Intelligence},
   keywords = {Deep learning (DL),Granular computing,Machine learning,Object detection,Object tracking,Video analysis},
   month = {9},
   pages = {6400-6429},
   publisher = {Springer},
   title = {Deep learning in multi-object detection and tracking: state of the art},
   volume = {51},
   year = {2021},
}

@misc{ITU_2160-0,
  title = {Framework and overall objectives of the future development of IMT for 2030 and beyond},
  author = {{ITU-R}},
  howpublished = {ITU-R Recommendation M.2160-0},
  month = {November},
  year = {2023},
  note = {M Series: Mobile, radiodetermination, amateur and related satellite services},
  url = {https://www.itu.int/rec/R-REC-M.2160-0-202311-I/en}
}

@misc{3GPP_about_us,
  title = {Introducing 3GPP},
  author = {{3GPP}},
  howpublished = {3GPP},
  month = {},
  year = {},
  note = {The 3rd Generation Partnership Project (3GPP) unites seven telecommunications standard development organizations, known as Organizational Partners’, providing their members with a stable environment to produce the Reports and Specifications that define the 3GPP system.},
  url = {https://www.3gpp.org/about-us/introducing-3gpp}
}
@misc{ETSI_5G_NR,
    author = {ETSI},
    title = {3rd Generation Partnership Project; Technical Specification Group Radio Access Network; NR; Architecture Description},
    year = {2022},
    url = {https://www.etsi.org/deliver/etsi_ts/123500_123599/123501/15.02.00_60/ts_123501v150200p.pdf},
    note = {Accessed on: December 2023},
}


@article{5G_apps,
   author = {Mohsen Attaran},
   doi = {10.1007/s12652-020-02521-x},
   issn = {18685145},
   issue = {5},
   journal = {Journal of Ambient Intelligence and Humanized Computing},
   keywords = {5G,5G networks,Cellular wireless networks,Enhanced mobile broadband (eMBB),Industrial Internet of Things (IIoT),Internet of Things (IoT),Internet of medical things (IoMT),Mobile communications,Wi-Fi 6},
   month = {5},
   pages = {5977-5993},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {The impact of 5G on the evolution of intelligent automation and industry digitization},
   volume = {14},
   year = {2023},
}

@article{Block_predict,
   abstract = {The sensitivity to blockages is a key challenge for millimeter wave and terahertz networks in 5G and beyond. Since these networks mainly rely on line-of-sight (LOS) links, sudden link blockages highly threaten the reliability of the networks. Further, when the LOS link is blocked, the network typically needs to hand off the user to another LOS basestation, which may incur critical time latency, especially if a search over a large codebook of narrow beams is needed. A promising way to tackle the reliability and latency challenges lies in enabling proaction in wireless networks. Proaction allows the network to anticipate future blockages, especially dynamic blockages, and initiate user hand-off beforehand. This article presents a complete machine learning framework for enabling proaction in wireless networks relying on visual data captured, for example, by red-green-blue (RGB) cameras deployed at the base stations. In particular, the article proposes a vision-aided wireless communication solution that utilizes bimodal machine learning to perform proactive blockage prediction and user hand-off. This is mainly achieved via a deep learning algorithm that learns from visual and wireless data how to predict incoming blockages. The predictions of this algorithm are used by the wireless network to proactively initiate hand-off decisions and avoid any unnecessary latency. The algorithm is developed on a vision-wireless dataset generated using the ViWi data-generation framework. Experimental results on two basestations with different cameras indicate that the algorithm is capable of accurately detecting incoming blockages more than ∼ 90% of the time. Such blockage prediction ability is directly reflected in the accuracy of proactive hand-off, which also approaches 87%. This highlights a promising direction for enabling high reliability and low latency in future wireless networks.},
   author = {Gouranga Charan and Muhammad Alrabeiah and Ahmed Alkhateeb},
   doi = {10.1109/TVT.2021.3104219},
   issn = {19399359},
   issue = {10},
   journal = {IEEE Transactions on Vehicular Technology},
   keywords = {Blockage prediction,computer vision.,deep learning,mmWave,proactive hand-off,terahertz},
   month = {10},
   pages = {10193-10208},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Vision-Aided 6G Wireless Communications: Blockage Prediction and Proactive Handoff},
   volume = {70},
   year = {2021},
}

@INPROCEEDINGS{Block_predict2,
  author={Alrabeiah, Muhammad and Hredzak, Andrew and Alkhateeb, Ahmed},
  booktitle={2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)}, 
  title={Millimeter Wave Base Stations with Cameras: Vision-Aided Beam and Blockage Prediction}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper investigates a novel research direction that leverages vision to help overcome the critical wireless communication challenges. In particular, this paper considers millimeter wave (mmWave) communication systems, which are principal components of 5G and beyond. These systems face two important challenges: (i) the large training overhead associated with selecting the optimal beam and (ii) the reliability challenge due to the high sensitivity to link blockages. Interestingly, most of the devices that employ mmWave arrays will likely also use cameras, such as 5G phones, self-driving vehicles, and virtual/augmented reality headsets. Therefore, we investigate the potential gains of employing cameras at the mmWave base stations and leveraging their visual data to help overcome the beam selection and blockage prediction challenges. To do that, this paper exploits computer vision and deep learning tools to predict mmWave beams and blockages directly from the camera RGB images and the sub-6GHz channels. The experimental results reveal interesting insights into the effectiveness of such solutions. For example, the deep learning model is capable of achieving over 90% beam prediction accuracy, which only requires snapping a shot of the scene and zero overhead.},
  keywords={},
  doi={10.1109/VTC2020-Spring48590.2020.9129369},
  ISSN={2577-2465},
  month={May},}

@INPROCEEDINGS{xApps,
  author={Bonati, Leonardo and Polese, Michele and D'Oro, Salvatore and Basagni, Stefano and Melodia, Tommaso},
  booktitle={European Wireless 2022; 27th European Wireless Conference}, 
  title={Intelligent Closed-loop RAN Control with xApps in OpenRAN Gym}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  doi={}}

@INPROCEEDINGS{YOLO,
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={You Only Look Once: Unified, Real-Time Object Detection}, 
  year={2016},
  volume={},
  number={},
  pages={779-788},
  doi={10.1109/CVPR.2016.91}}

@article{SSD,
  title={SSD: Single Shot MultiBox Detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  journal={European conference on computer vision},
  pages={21--37},
  year={2016},
  publisher={Springer}
}

@article{YOLOv3,
  title={YOLOv3: An Incremental Improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018},
  url={https://arxiv.org/pdf/1804.02767.pdf}
}

@ARTICLE{FasterRCNN,
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
  year={2017},
  volume={39},
  number={6},
  pages={1137-1149},
  doi={10.1109/TPAMI.2016.2577031}}

@misc{ORAN-ARCH, title = {O-RAN Architecture}, author = {O-RAN Software Community}, url = {https://docs.o-ran-sc.org/en/e-release/architecture/architecture.html}, note     = {Accessed on: January 03, 2024} }


@misc{Trad_RAN,
  author = {Lumenci},
  title = {Evolution of RAN: The Road from 1G to 5G},
  year = {2023},
  url = {https://www.lumenci.com/research-articles/evolution-of-ran-the-road-from-1g-to-5g},
  note = {Accessed: December 26, 2023}
}

@misc{cRAN,
  author = {IAS Gyan},
  title = {Radio Access Network (RAN)},
  year = {2023},
  url = {https://www.iasgyan.in/daily-current-affairs/radio-access-network-ran},
  note = {Accessed: December 26, 2023}
}

@techreport{gnb_diss,
  author = {{European Telecommunications Standards Institute (ETSI)}},
  title = {{NG-RAN; Architecture description, ETSI TS 138 401 V16.3.0}},
  year = {2022},
  month = {March},
  institution = {ETSI},
  url = {https://www.etsi.org/deliver/etsi_ts/138400_138499/138401/16.03.00_60/ts_138401v160300p.pdf},
  note = {Accessed: December 26, 2023}
}

@INPROCEEDINGS{siam,
  author={Voigtlaender, Paul and Luiten, Jonathon and Torr, Philip H.S. and Leibe, Bastian},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Siam R-CNN: Visual Tracking by Re-Detection}, 
  year={2020},
  volume={},
  number={},
  pages={6577-6587},
  doi={10.1109/CVPR42600.2020.00661}}

@INPROCEEDINGS{DeepSORT,
  author={Pujara, Abhijeet and Bhamare, Mamta},
  booktitle={2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={DeepSORT: Real Time \& Multi-Object Detection and Tracking with YOLO and TensorFlow}, 
  year={2022},
  volume={},
  number={},
  pages={456-460},
  doi={10.1109/ICAISS55157.2022.10011018}}

@article{SORT,
  author       = {Nicolai Wojke and
                  Alex Bewley and
                  Dietrich Paulus},
  title        = {Simple Online and Realtime Tracking with a Deep Association Metric},
  journal      = {CoRR},
  volume       = {abs/1703.07402},
  year         = {2017},
  url          = {http://arxiv.org/abs/1703.07402},
  eprinttype    = {arXiv},
  eprint       = {1703.07402},
  timestamp    = {Mon, 13 Aug 2018 16:47:39 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/WojkeBP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{KCF,
  author       = {Jo{\~{a}}o F. Henriques and
                  Rui Caseiro and
                  Pedro Martins and
                  Jorge Batista},
  title        = {High-Speed Tracking with Kernelized Correlation Filters},
  journal      = {CoRR},
  volume       = {abs/1404.7584},
  year         = {2014},
  url          = {http://arxiv.org/abs/1404.7584},
  eprinttype    = {arXiv},
  eprint       = {1404.7584},
  timestamp    = {Fri, 02 Oct 2020 09:06:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HenriquesCMB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{1vs2,
  author={Jiao, Licheng and Zhang, Fan and Liu, Fang and Yang, Shuyuan and Li, Lingling and Feng, Zhixi and Qu, Rong},
  journal={IEEE Access}, 
  title={A Survey of Deep Learning-Based Object Detection}, 
  year={2019},
  volume={7},
  number={},
  pages={128837-128868},
  doi={10.1109/ACCESS.2019.2939201}}

@techreport{converge2023_usecases,
  author    = {P. M. and et al.},
  title     = {Converge - Telecommunications and Computer Vision Convergence Tools
               for Research Infrastructures D1.1: Requirements and use cases},
  year      = {2023},
  institution = {Converge},
  note      = {Access restricted to authorized personnel}
}

@techreport{converge2023_specs,
  author    = {P. M. and et al.},
  title     = {Converge - Telecommunications and Computer Vision Convergence Tools
               for Research Infrastructures D1.2: Specification of Interfaces and Access Policies (Initial)},
  year      = {2023},
  institution = {Converge},
  note      = {Access restricted to authorized personnel}
}

@misc{ultralytics_docs,
  title    = {Ultralytics Documentation},
  author   = {Ultralytics Team},
  year     = {2024},
  url      = {https://docs.ultralytics.com},
  note     = {Accessed on: January 03, 2024},
}

@article{COCO,
  author       = {Tsung{-}Yi Lin and
                  Michael Maire and
                  Serge J. Belongie and
                  Lubomir D. Bourdev and
                  Ross B. Girshick and
                  James Hays and
                  Pietro Perona and
                  Deva Ramanan and
                  Piotr Doll{\'{a}}r and
                  C. Lawrence Zitnick},
  title        = {Microsoft {COCO:} Common Objects in Context},
  journal      = {CoRR},
  volume       = {abs/1405.0312},
  year         = {2014},
  url          = {http://arxiv.org/abs/1405.0312},
  eprinttype    = {arXiv},
  eprint       = {1405.0312},
  timestamp    = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{yolov7,
      title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors}, 
      author={Chien-Yao Wang and Alexey Bochkovskiy and Hong-Yuan Mark Liao},
      year={2022},
      eprint={2207.02696},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{YOLO_compare,
  author={L, Dhruthi and Megharaj, Praveen K and P, Pranav and Kiran, Niharika and P, Asha Rani K and S, Gowrishankar},
  booktitle={2023 4th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={State-of-the-Art Object Detection: An Overview of YOLO Variants and their Performance}, 
  year={2023},
  volume={},
  number={},
  pages={1018-1024},
  doi={10.1109/ICOSEC58147.2023.10276030}}

@misc{converge_site,
    title={Telecommunications and Computer Vision
Convergence Tools for Research Infrastructures},
    author={CONVERGE},
     year     = {2024},
    note = {Accessed on: January 08, 2024},
    url= https://converge-project.eu/
}








